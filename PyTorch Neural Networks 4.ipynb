{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Defining new autograd functions\n",
    "\n",
    "In PyTorch we can easily define our own autograd operator by defining a subclass of torch.autograd.Function and implementing the forward and backward functions. We can then use our new autograd operator by constructing an instance and calling it like a function, passing Tensors containing input data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32772474.0\n",
      "1 34797584.0\n",
      "2 39464240.0\n",
      "3 39190744.0\n",
      "4 29969980.0\n",
      "5 16956194.0\n",
      "6 7743437.5\n",
      "7 3491127.75\n",
      "8 1857910.625\n",
      "9 1215071.25\n",
      "10 914041.3125\n",
      "11 737843.3125\n",
      "12 615360.6875\n",
      "13 521814.65625\n",
      "14 446892.0\n",
      "15 385454.125\n",
      "16 334393.875\n",
      "17 291574.34375\n",
      "18 255395.59375\n",
      "19 224658.6875\n",
      "20 198357.734375\n",
      "21 175747.609375\n",
      "22 156214.234375\n",
      "23 139268.28125\n",
      "24 124476.359375\n",
      "25 111529.8828125\n",
      "26 100175.1015625\n",
      "27 90187.5703125\n",
      "28 81374.8125\n",
      "29 73577.140625\n",
      "30 66653.5234375\n",
      "31 60481.078125\n",
      "32 54966.046875\n",
      "33 50025.23828125\n",
      "34 45598.41796875\n",
      "35 41621.765625\n",
      "36 38040.91015625\n",
      "37 34811.95703125\n",
      "38 31891.271484375\n",
      "39 29246.474609375\n",
      "40 26850.9453125\n",
      "41 24673.46875\n",
      "42 22692.921875\n",
      "43 20889.822265625\n",
      "44 19245.728515625\n",
      "45 17745.619140625\n",
      "46 16375.1259765625\n",
      "47 15122.6455078125\n",
      "48 13975.779296875\n",
      "49 12924.609375\n",
      "50 11960.6083984375\n",
      "51 11076.25390625\n",
      "52 10263.673828125\n",
      "53 9516.46484375\n",
      "54 8828.9951171875\n",
      "55 8196.22265625\n",
      "56 7612.61865234375\n",
      "57 7074.4189453125\n",
      "58 6577.650390625\n",
      "59 6118.8837890625\n",
      "60 5695.52734375\n",
      "61 5305.0615234375\n",
      "62 4943.93896484375\n",
      "63 4609.3935546875\n",
      "64 4299.40478515625\n",
      "65 4012.125244140625\n",
      "66 3745.5283203125\n",
      "67 3498.08544921875\n",
      "68 3268.30224609375\n",
      "69 3054.929443359375\n",
      "70 2856.568359375\n",
      "71 2671.981689453125\n",
      "72 2500.2265625\n",
      "73 2340.335693359375\n",
      "74 2191.44970703125\n",
      "75 2052.739990234375\n",
      "76 1923.5438232421875\n",
      "77 1803.0684814453125\n",
      "78 1690.578857421875\n",
      "79 1585.6302490234375\n",
      "80 1487.6336669921875\n",
      "81 1396.0601806640625\n",
      "82 1310.48876953125\n",
      "83 1230.5321044921875\n",
      "84 1155.7509765625\n",
      "85 1085.7686767578125\n",
      "86 1020.2825317382812\n",
      "87 958.9749755859375\n",
      "88 901.5601196289062\n",
      "89 847.7881469726562\n",
      "90 797.4432373046875\n",
      "91 750.2349853515625\n",
      "92 705.96923828125\n",
      "93 664.49951171875\n",
      "94 625.5590209960938\n",
      "95 589.0213012695312\n",
      "96 554.7334594726562\n",
      "97 522.5480346679688\n",
      "98 492.3074035644531\n",
      "99 463.9012145996094\n",
      "100 437.2122497558594\n",
      "101 412.1249084472656\n",
      "102 388.5533752441406\n",
      "103 366.40240478515625\n",
      "104 345.55224609375\n",
      "105 325.9573669433594\n",
      "106 307.5142822265625\n",
      "107 290.1565246582031\n",
      "108 273.82049560546875\n",
      "109 258.4559020996094\n",
      "110 243.99139404296875\n",
      "111 230.3721923828125\n",
      "112 217.54502868652344\n",
      "113 205.45494079589844\n",
      "114 194.06983947753906\n",
      "115 183.3392333984375\n",
      "116 173.22885131835938\n",
      "117 163.6934051513672\n",
      "118 154.69346618652344\n",
      "119 146.20094299316406\n",
      "120 138.2000274658203\n",
      "121 130.64247131347656\n",
      "122 123.51449584960938\n",
      "123 116.78723907470703\n",
      "124 110.43875122070312\n",
      "125 104.44817352294922\n",
      "126 98.79129028320312\n",
      "127 93.45570373535156\n",
      "128 88.41140747070312\n",
      "129 83.64751434326172\n",
      "130 79.1474609375\n",
      "131 74.90121459960938\n",
      "132 70.88352966308594\n",
      "133 67.08959197998047\n",
      "134 63.50513458251953\n",
      "135 60.11567687988281\n",
      "136 56.914588928222656\n",
      "137 53.89146423339844\n",
      "138 51.029052734375\n",
      "139 48.322303771972656\n",
      "140 45.762718200683594\n",
      "141 43.344051361083984\n",
      "142 41.055057525634766\n",
      "143 38.88937759399414\n",
      "144 36.841495513916016\n",
      "145 34.9038200378418\n",
      "146 33.07276153564453\n",
      "147 31.33957862854004\n",
      "148 29.69750213623047\n",
      "149 28.143518447875977\n",
      "150 26.672332763671875\n",
      "151 25.28169822692871\n",
      "152 23.96359634399414\n",
      "153 22.71527099609375\n",
      "154 21.53384017944336\n",
      "155 20.415632247924805\n",
      "156 19.358257293701172\n",
      "157 18.35489845275879\n",
      "158 17.404430389404297\n",
      "159 16.504541397094727\n",
      "160 15.652175903320312\n",
      "161 14.844507217407227\n",
      "162 14.079035758972168\n",
      "163 13.354284286499023\n",
      "164 12.667140007019043\n",
      "165 12.01757526397705\n",
      "166 11.400897026062012\n",
      "167 10.815804481506348\n",
      "168 10.26156997680664\n",
      "169 9.736705780029297\n",
      "170 9.238836288452148\n",
      "171 8.766271591186523\n",
      "172 8.319278717041016\n",
      "173 7.895119667053223\n",
      "174 7.493317127227783\n",
      "175 7.111965656280518\n",
      "176 6.750336647033691\n",
      "177 6.407380104064941\n",
      "178 6.082202434539795\n",
      "179 5.773734092712402\n",
      "180 5.480967044830322\n",
      "181 5.203341484069824\n",
      "182 4.940417766571045\n",
      "183 4.690999984741211\n",
      "184 4.453697681427002\n",
      "185 4.2288360595703125\n",
      "186 4.015942096710205\n",
      "187 3.813717842102051\n",
      "188 3.6214306354522705\n",
      "189 3.439293622970581\n",
      "190 3.2664709091186523\n",
      "191 3.1025497913360596\n",
      "192 2.9468295574188232\n",
      "193 2.798879861831665\n",
      "194 2.658982753753662\n",
      "195 2.5256590843200684\n",
      "196 2.3992695808410645\n",
      "197 2.2792041301727295\n",
      "198 2.1653294563293457\n",
      "199 2.057265520095825\n",
      "200 1.9545719623565674\n",
      "201 1.8571536540985107\n",
      "202 1.7646112442016602\n",
      "203 1.6766728162765503\n",
      "204 1.5932960510253906\n",
      "205 1.5139272212982178\n",
      "206 1.4387640953063965\n",
      "207 1.3673484325408936\n",
      "208 1.2995809316635132\n",
      "209 1.2351208925247192\n",
      "210 1.1737768650054932\n",
      "211 1.1157214641571045\n",
      "212 1.060417652130127\n",
      "213 1.0078744888305664\n",
      "214 0.9581187963485718\n",
      "215 0.9108657240867615\n",
      "216 0.8659231066703796\n",
      "217 0.8231553435325623\n",
      "218 0.7825543880462646\n",
      "219 0.7439882755279541\n",
      "220 0.7072939872741699\n",
      "221 0.6724861860275269\n",
      "222 0.6394035816192627\n",
      "223 0.6079990267753601\n",
      "224 0.5780589580535889\n",
      "225 0.5497020483016968\n",
      "226 0.522702157497406\n",
      "227 0.4970225989818573\n",
      "228 0.47262322902679443\n",
      "229 0.4495215117931366\n",
      "230 0.42751529812812805\n",
      "231 0.4065600335597992\n",
      "232 0.38665035367012024\n",
      "233 0.36773809790611267\n",
      "234 0.3497549295425415\n",
      "235 0.33265841007232666\n",
      "236 0.31641173362731934\n",
      "237 0.30103403329849243\n",
      "238 0.2863410413265228\n",
      "239 0.2724098265171051\n",
      "240 0.2591257393360138\n",
      "241 0.24649642407894135\n",
      "242 0.23447702825069427\n",
      "243 0.2230692356824875\n",
      "244 0.2121921181678772\n",
      "245 0.20189301669597626\n",
      "246 0.19208413362503052\n",
      "247 0.18274162709712982\n",
      "248 0.17384567856788635\n",
      "249 0.16542652249336243\n",
      "250 0.1573982685804367\n",
      "251 0.14976124465465546\n",
      "252 0.1425349861383438\n",
      "253 0.1356268674135208\n",
      "254 0.12904009222984314\n",
      "255 0.12278353422880173\n",
      "256 0.11688762903213501\n",
      "257 0.11124185472726822\n",
      "258 0.10585761815309525\n",
      "259 0.10076405853033066\n",
      "260 0.09587576240301132\n",
      "261 0.09124823659658432\n",
      "262 0.08684715628623962\n",
      "263 0.08267775177955627\n",
      "264 0.07866592705249786\n",
      "265 0.07488057762384415\n",
      "266 0.07128851860761642\n",
      "267 0.067865751683712\n",
      "268 0.06458473205566406\n",
      "269 0.06147592142224312\n",
      "270 0.05852940306067467\n",
      "271 0.05572138726711273\n",
      "272 0.05303100496530533\n",
      "273 0.05050884932279587\n",
      "274 0.048080842941999435\n",
      "275 0.04577447474002838\n",
      "276 0.043571025133132935\n",
      "277 0.041507747024297714\n",
      "278 0.039518844336271286\n",
      "279 0.037630438804626465\n",
      "280 0.03583763912320137\n",
      "281 0.03411044925451279\n",
      "282 0.03249034285545349\n",
      "283 0.030939200893044472\n",
      "284 0.02947036363184452\n",
      "285 0.02807951159775257\n",
      "286 0.026732781901955605\n",
      "287 0.025462741032242775\n",
      "288 0.024263054132461548\n",
      "289 0.023111877962946892\n",
      "290 0.022016428411006927\n",
      "291 0.020971812307834625\n",
      "292 0.019960829988121986\n",
      "293 0.019026057794690132\n",
      "294 0.018138783052563667\n",
      "295 0.017281625419855118\n",
      "296 0.01646004617214203\n",
      "297 0.01568828523159027\n",
      "298 0.014954459853470325\n",
      "299 0.014254221692681313\n",
      "300 0.013585424982011318\n",
      "301 0.012952654622495174\n",
      "302 0.012350485660135746\n",
      "303 0.01177569292485714\n",
      "304 0.011232174932956696\n",
      "305 0.010710782371461391\n",
      "306 0.010216983035206795\n",
      "307 0.00974132027477026\n",
      "308 0.009294169023633003\n",
      "309 0.008867017924785614\n",
      "310 0.008460301905870438\n",
      "311 0.00806435290724039\n",
      "312 0.00770103232935071\n",
      "313 0.007346101570874453\n",
      "314 0.007014373783022165\n",
      "315 0.00669731292873621\n",
      "316 0.006387296598404646\n",
      "317 0.006103895604610443\n",
      "318 0.005831289105117321\n",
      "319 0.005567846354097128\n",
      "320 0.005318101029843092\n",
      "321 0.005081784445792437\n",
      "322 0.004862045869231224\n",
      "323 0.00464323116466403\n",
      "324 0.004440145567059517\n",
      "325 0.004247533623129129\n",
      "326 0.004060253966599703\n",
      "327 0.0038805806543678045\n",
      "328 0.003711657365784049\n",
      "329 0.003551321802660823\n",
      "330 0.0033998829312622547\n",
      "331 0.0032548524904996157\n",
      "332 0.003118036314845085\n",
      "333 0.0029831614810973406\n",
      "334 0.002860231092199683\n",
      "335 0.0027370203752070665\n",
      "336 0.002621803665533662\n",
      "337 0.0025163160171359777\n",
      "338 0.0024105715565383434\n",
      "339 0.0023149268236011267\n",
      "340 0.0022186236456036568\n",
      "341 0.002129889326170087\n",
      "342 0.00204253988340497\n",
      "343 0.0019619858358055353\n",
      "344 0.001883810618892312\n",
      "345 0.0018097669817507267\n",
      "346 0.0017372536240145564\n",
      "347 0.0016697990940883756\n",
      "348 0.0016060239868238568\n",
      "349 0.001544071128591895\n",
      "350 0.001484499080106616\n",
      "351 0.0014292866690084338\n",
      "352 0.0013741380535066128\n",
      "353 0.001323185977526009\n",
      "354 0.001272454159334302\n",
      "355 0.0012257759226486087\n",
      "356 0.0011807236587628722\n",
      "357 0.001137628685683012\n",
      "358 0.0010972011368721724\n",
      "359 0.0010579860536381602\n",
      "360 0.0010193585185334086\n",
      "361 0.0009842580184340477\n",
      "362 0.0009500244632363319\n",
      "363 0.0009157255990430713\n",
      "364 0.0008841605740599334\n",
      "365 0.0008545697783119977\n",
      "366 0.000825436960440129\n",
      "367 0.0007968567661009729\n",
      "368 0.0007699152338318527\n",
      "369 0.0007454539882019162\n",
      "370 0.0007210210314951837\n",
      "371 0.0006970776012167335\n",
      "372 0.000674739945679903\n",
      "373 0.000654879491776228\n",
      "374 0.0006332217017188668\n",
      "375 0.0006126076332293451\n",
      "376 0.0005931293708272278\n",
      "377 0.0005745707312598825\n",
      "378 0.0005570329958572984\n",
      "379 0.0005402361275628209\n",
      "380 0.0005240618484094739\n",
      "381 0.0005079408874735236\n",
      "382 0.0004929963615722954\n",
      "383 0.00047814787831157446\n",
      "384 0.00046428150380961597\n",
      "385 0.0004508664133027196\n",
      "386 0.00043742769048549235\n",
      "387 0.0004251179634593427\n",
      "388 0.0004126837011426687\n",
      "389 0.0004014686564914882\n",
      "390 0.000389767432352528\n",
      "391 0.0003793849900830537\n",
      "392 0.0003690978919621557\n",
      "393 0.00035859018680639565\n",
      "394 0.0003489271621219814\n",
      "395 0.0003398441185709089\n",
      "396 0.00033046817407011986\n",
      "397 0.0003214870230294764\n",
      "398 0.0003130573022644967\n",
      "399 0.00030427664751186967\n",
      "400 0.0002964915183838457\n",
      "401 0.0002883387787733227\n",
      "402 0.00028078097966499627\n",
      "403 0.00027364247944206\n",
      "404 0.0002665844513103366\n",
      "405 0.0002599213912617415\n",
      "406 0.00025335195823572576\n",
      "407 0.00024776102509349585\n",
      "408 0.00024106766795739532\n",
      "409 0.00023527262965217233\n",
      "410 0.0002300977212144062\n",
      "411 0.0002242033078800887\n",
      "412 0.0002196298009948805\n",
      "413 0.00021386386652011424\n",
      "414 0.00020874914480373263\n",
      "415 0.00020344067888800055\n",
      "416 0.00019928203255403787\n",
      "417 0.0001949420984601602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 0.00019025443179998547\n",
      "419 0.0001861627824837342\n",
      "420 0.00018186139641329646\n",
      "421 0.00017762243805918843\n",
      "422 0.00017407358973287046\n",
      "423 0.0001700558204902336\n",
      "424 0.0001661398564465344\n",
      "425 0.00016269586922135204\n",
      "426 0.00015920177975203842\n",
      "427 0.0001555293711135164\n",
      "428 0.00015228443953674287\n",
      "429 0.00014878281217534095\n",
      "430 0.0001455090387025848\n",
      "431 0.0001430082629667595\n",
      "432 0.0001393901911797002\n",
      "433 0.00013678503455594182\n",
      "434 0.00013393785047810525\n",
      "435 0.0001310396910412237\n",
      "436 0.00012833144864998758\n",
      "437 0.000125556078273803\n",
      "438 0.0001234533847309649\n",
      "439 0.00012115157005609944\n",
      "440 0.00011887362052220851\n",
      "441 0.00011667267244774848\n",
      "442 0.00011443143739597872\n",
      "443 0.00011235303099965677\n",
      "444 0.00010994490003213286\n",
      "445 0.00010822820331668481\n",
      "446 0.0001065387186827138\n",
      "447 0.00010415763244964182\n",
      "448 0.00010214298526989296\n",
      "449 0.00010056769679067656\n",
      "450 9.865203173831105e-05\n",
      "451 9.679447975941002e-05\n",
      "452 9.508022776572034e-05\n",
      "453 9.35966891120188e-05\n",
      "454 9.176741150440648e-05\n",
      "455 9.035056427819654e-05\n",
      "456 8.877411164576188e-05\n",
      "457 8.698370220372453e-05\n",
      "458 8.528315083822235e-05\n",
      "459 8.414780313614756e-05\n",
      "460 8.272946433862671e-05\n",
      "461 8.105961751425639e-05\n",
      "462 7.9959056165535e-05\n",
      "463 7.861934864195064e-05\n",
      "464 7.730077049927786e-05\n",
      "465 7.58935566409491e-05\n",
      "466 7.455786544596776e-05\n",
      "467 7.36722067813389e-05\n",
      "468 7.23943448974751e-05\n",
      "469 7.107718556653708e-05\n",
      "470 7.01072858646512e-05\n",
      "471 6.89181251800619e-05\n",
      "472 6.763824057998136e-05\n",
      "473 6.682899402221665e-05\n",
      "474 6.562230555573478e-05\n",
      "475 6.460147415054962e-05\n",
      "476 6.369777111103758e-05\n",
      "477 6.285922427196056e-05\n",
      "478 6.183154619066045e-05\n",
      "479 6.10791685176082e-05\n",
      "480 6.012193625792861e-05\n",
      "481 5.910644176765345e-05\n",
      "482 5.8288158470531926e-05\n",
      "483 5.74743389734067e-05\n",
      "484 5.648988008033484e-05\n",
      "485 5.596733171842061e-05\n",
      "486 5.5200362112373114e-05\n",
      "487 5.431753379525617e-05\n",
      "488 5.365134711610153e-05\n",
      "489 5.31413170392625e-05\n",
      "490 5.235380376689136e-05\n",
      "491 5.158613930689171e-05\n",
      "492 5.084712756797671e-05\n",
      "493 4.998282020096667e-05\n",
      "494 4.938647543895058e-05\n",
      "495 4.885591260972433e-05\n",
      "496 4.812393308384344e-05\n",
      "497 4.735593392979354e-05\n",
      "498 4.68438993266318e-05\n",
      "499 4.633813659893349e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing \n",
    "    torch.autograd.Function and implementing the forward and backward passes \n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive t=a Tensor conatining the input and return a\n",
    "        Tensor containgn the output. ctx is a context object that can be used to stash information \n",
    "        for backward computation. You can cache arbitrary objects for use in the backward pass\n",
    "        using the ctx.save_for_backward method. \n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing a gradient of the loss with respect \n",
    "        to the output, and we need to compute the gradient of the loss with respect to the input \n",
    "        \"\"\"\n",
    "        \n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input \n",
    "    \n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "input_dimension = 1000\n",
    "hidden_dimension = 100\n",
    "output_dimension = 10\n",
    "\n",
    "# Generate random data\n",
    "x = torch.randn(batch_size, input_dimension, device = device, dtype = dtype)\n",
    "y = torch.randn(batch_size, output_dimension, device = device, dtype = dtype)\n",
    "\n",
    "# Initialize random weights \n",
    "weight1 = torch.randn(input_dimension, hidden_dimension, device = device, dtype = dtype, requires_grad=True)\n",
    "weight2 = torch.randn(hidden_dimension, output_dimension, device = device, dtype = dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for n in range(500):\n",
    "    #To apply our Function, we use Funciton.apply method\n",
    "    # We alias this as 'relu'\n",
    "    relu = MyReLU.apply\n",
    "    \n",
    "    #Forward pass: compute predicted y using operations: \n",
    "    # Compute ReLU using our suctom autograd operation\n",
    "    y_pred = relu(x.mm(weight1)).mm(weight2)\n",
    "    \n",
    "    #Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(n, loss.item())\n",
    "    \n",
    "    # Use autograd to compute the backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update weights sing gradient descent\n",
    "    with torch.no_grad():\n",
    "        weight1 -= learning_rate * weight1.grad\n",
    "        weight2 -= learning_rate * weight2.grad\n",
    "        \n",
    "        #Manually zero the gradients after updating weights \n",
    "        weight1.grad.zero_()\n",
    "        weight2.grad.zero_()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
