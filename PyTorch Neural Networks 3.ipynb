{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd \n",
    "## PyTorch: Tensors and autograd \n",
    "\n",
    "To automate the process of back and forward propagation in eural networks, we can use automatic differentiation. AUtograd package provides PyTorch with this functionality. The forward pass will define a computational graph, nodes in the graph will be Tensors, and egdes will be functions that produce output Tensors from input Tensors. Backprop through this graph then allows you to easily compute gradients. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 52343052.0\n",
      "1 62104132.0\n",
      "2 64333412.0\n",
      "3 44568704.0\n",
      "4 18772802.0\n",
      "5 6148066.5\n",
      "6 2702086.0\n",
      "7 1763478.625\n",
      "8 1370367.0\n",
      "9 1123478.25\n",
      "10 939798.0625\n",
      "11 795082.3125\n",
      "12 678384.625\n",
      "13 582988.4375\n",
      "14 504195.28125\n",
      "15 438517.78125\n",
      "16 383282.0\n",
      "17 336574.84375\n",
      "18 296847.53125\n",
      "19 262806.0625\n",
      "20 233469.71875\n",
      "21 208054.234375\n",
      "22 185951.359375\n",
      "23 166641.75\n",
      "24 149727.609375\n",
      "25 134852.6875\n",
      "26 121731.015625\n",
      "27 110149.6640625\n",
      "28 99894.2890625\n",
      "29 90755.5859375\n",
      "30 82590.453125\n",
      "31 75276.125\n",
      "32 68714.3046875\n",
      "33 62813.80078125\n",
      "34 57497.40234375\n",
      "35 52699.0703125\n",
      "36 48358.3125\n",
      "37 44426.83203125\n",
      "38 40858.5390625\n",
      "39 37616.5546875\n",
      "40 34672.57421875\n",
      "41 31993.349609375\n",
      "42 29547.08984375\n",
      "43 27312.873046875\n",
      "44 25273.064453125\n",
      "45 23406.07421875\n",
      "46 21694.986328125\n",
      "47 20124.40625\n",
      "48 18681.275390625\n",
      "49 17354.759765625\n",
      "50 16134.103515625\n",
      "51 15011.765625\n",
      "52 13979.0087890625\n",
      "53 13025.23046875\n",
      "54 12143.1845703125\n",
      "55 11327.1083984375\n",
      "56 10571.8056640625\n",
      "57 9872.275390625\n",
      "58 9223.591796875\n",
      "59 8621.6806640625\n",
      "60 8062.98095703125\n",
      "61 7543.93505859375\n",
      "62 7061.3037109375\n",
      "63 6612.65380859375\n",
      "64 6195.01318359375\n",
      "65 5806.2978515625\n",
      "66 5443.98974609375\n",
      "67 5106.2861328125\n",
      "68 4791.41552734375\n",
      "69 4497.60986328125\n",
      "70 4223.2607421875\n",
      "71 3966.962646484375\n",
      "72 3727.4990234375\n",
      "73 3503.7255859375\n",
      "74 3294.490478515625\n",
      "75 3098.6142578125\n",
      "76 2915.27490234375\n",
      "77 2743.704833984375\n",
      "78 2582.95263671875\n",
      "79 2432.28173828125\n",
      "80 2291.022705078125\n",
      "81 2158.5615234375\n",
      "82 2034.275146484375\n",
      "83 1917.6356201171875\n",
      "84 1808.168212890625\n",
      "85 1705.3758544921875\n",
      "86 1608.815185546875\n",
      "87 1518.09375\n",
      "88 1432.798095703125\n",
      "89 1352.603759765625\n",
      "90 1277.2144775390625\n",
      "91 1206.266845703125\n",
      "92 1139.51318359375\n",
      "93 1076.6767578125\n",
      "94 1017.5256958007812\n",
      "95 961.8141479492188\n",
      "96 909.3477172851562\n",
      "97 859.9017333984375\n",
      "98 813.3091430664062\n",
      "99 769.3820190429688\n",
      "100 727.9701538085938\n",
      "101 688.9072265625\n",
      "102 652.0570068359375\n",
      "103 617.2914428710938\n",
      "104 584.4735107421875\n",
      "105 553.503662109375\n",
      "106 524.2648315429688\n",
      "107 496.647216796875\n",
      "108 470.5583190917969\n",
      "109 445.9288635253906\n",
      "110 422.6451416015625\n",
      "111 400.63494873046875\n",
      "112 379.8297119140625\n",
      "113 360.15997314453125\n",
      "114 341.5566711425781\n",
      "115 323.9578857421875\n",
      "116 307.3515319824219\n",
      "117 291.6419677734375\n",
      "118 276.7774353027344\n",
      "119 262.70489501953125\n",
      "120 249.38121032714844\n",
      "121 236.76890563964844\n",
      "122 224.82330322265625\n",
      "123 213.50552368164062\n",
      "124 202.78750610351562\n",
      "125 192.63204956054688\n",
      "126 183.01254272460938\n",
      "127 173.89266967773438\n",
      "128 165.2465362548828\n",
      "129 157.04811096191406\n",
      "130 149.27915954589844\n",
      "131 141.90711975097656\n",
      "132 134.91546630859375\n",
      "133 128.28164672851562\n",
      "134 121.98807525634766\n",
      "135 116.01533508300781\n",
      "136 110.34635925292969\n",
      "137 104.96681213378906\n",
      "138 99.86103820800781\n",
      "139 95.01111602783203\n",
      "140 90.41162109375\n",
      "141 86.04306030273438\n",
      "142 81.89480590820312\n",
      "143 77.9527359008789\n",
      "144 74.20915222167969\n",
      "145 70.65094757080078\n",
      "146 67.269287109375\n",
      "147 64.05680084228516\n",
      "148 61.006717681884766\n",
      "149 58.10258102416992\n",
      "150 55.3414421081543\n",
      "151 52.716922760009766\n",
      "152 50.22079086303711\n",
      "153 47.84607696533203\n",
      "154 45.58845520019531\n",
      "155 43.44020462036133\n",
      "156 41.39630889892578\n",
      "157 39.45252227783203\n",
      "158 37.602054595947266\n",
      "159 35.841209411621094\n",
      "160 34.16554641723633\n",
      "161 32.57052230834961\n",
      "162 31.05314064025879\n",
      "163 29.60788345336914\n",
      "164 28.232011795043945\n",
      "165 26.9213924407959\n",
      "166 25.673982620239258\n",
      "167 24.485980987548828\n",
      "168 23.354734420776367\n",
      "169 22.276412963867188\n",
      "170 21.250112533569336\n",
      "171 20.271711349487305\n",
      "172 19.340240478515625\n",
      "173 18.452606201171875\n",
      "174 17.606698989868164\n",
      "175 16.800540924072266\n",
      "176 16.032184600830078\n",
      "177 15.300460815429688\n",
      "178 14.602578163146973\n",
      "179 13.937019348144531\n",
      "180 13.303117752075195\n",
      "181 12.698434829711914\n",
      "182 12.121769905090332\n",
      "183 11.57256031036377\n",
      "184 11.048748970031738\n",
      "185 10.549530029296875\n",
      "186 10.073140144348145\n",
      "187 9.618619918823242\n",
      "188 9.185615539550781\n",
      "189 8.771921157836914\n",
      "190 8.377294540405273\n",
      "191 8.001444816589355\n",
      "192 7.642359256744385\n",
      "193 7.300151348114014\n",
      "194 6.973635673522949\n",
      "195 6.661740779876709\n",
      "196 6.364691257476807\n",
      "197 6.080420970916748\n",
      "198 5.809632301330566\n",
      "199 5.550779819488525\n",
      "200 5.303976535797119\n",
      "201 5.068360805511475\n",
      "202 4.843017101287842\n",
      "203 4.628448009490967\n",
      "204 4.423302173614502\n",
      "205 4.2275848388671875\n",
      "206 4.040524005889893\n",
      "207 3.8617727756500244\n",
      "208 3.6914546489715576\n",
      "209 3.528646469116211\n",
      "210 3.373194694519043\n",
      "211 3.224613904953003\n",
      "212 3.0826151371002197\n",
      "213 2.947092056274414\n",
      "214 2.817681074142456\n",
      "215 2.6940720081329346\n",
      "216 2.5759105682373047\n",
      "217 2.463141441345215\n",
      "218 2.355215072631836\n",
      "219 2.2521934509277344\n",
      "220 2.153690814971924\n",
      "221 2.059784173965454\n",
      "222 1.9697333574295044\n",
      "223 1.883941888809204\n",
      "224 1.8017009496688843\n",
      "225 1.72328782081604\n",
      "226 1.64838707447052\n",
      "227 1.5768110752105713\n",
      "228 1.508113980293274\n",
      "229 1.4425724744796753\n",
      "230 1.380232810974121\n",
      "231 1.3202362060546875\n",
      "232 1.2629680633544922\n",
      "233 1.2083488702774048\n",
      "234 1.1560386419296265\n",
      "235 1.1059850454330444\n",
      "236 1.0582655668258667\n",
      "237 1.0125774145126343\n",
      "238 0.9688871502876282\n",
      "239 0.9270359873771667\n",
      "240 0.8871173858642578\n",
      "241 0.8489478826522827\n",
      "242 0.8123162984848022\n",
      "243 0.777539074420929\n",
      "244 0.744032084941864\n",
      "245 0.7120091915130615\n",
      "246 0.6814759969711304\n",
      "247 0.6522656083106995\n",
      "248 0.6241760849952698\n",
      "249 0.5974860787391663\n",
      "250 0.5718901753425598\n",
      "251 0.5474390983581543\n",
      "252 0.5240225791931152\n",
      "253 0.5016025304794312\n",
      "254 0.48014745116233826\n",
      "255 0.45961007475852966\n",
      "256 0.4399567246437073\n",
      "257 0.4212285578250885\n",
      "258 0.4033259153366089\n",
      "259 0.3861134946346283\n",
      "260 0.36960986256599426\n",
      "261 0.3539194166660309\n",
      "262 0.3388351798057556\n",
      "263 0.32442888617515564\n",
      "264 0.31059107184410095\n",
      "265 0.2974057197570801\n",
      "266 0.2848072648048401\n",
      "267 0.27265578508377075\n",
      "268 0.26106342673301697\n",
      "269 0.25002235174179077\n",
      "270 0.23940864205360413\n",
      "271 0.22928573191165924\n",
      "272 0.2195872962474823\n",
      "273 0.2102893590927124\n",
      "274 0.2013511210680008\n",
      "275 0.1928626447916031\n",
      "276 0.18468546867370605\n",
      "277 0.1768631935119629\n",
      "278 0.1694096326828003\n",
      "279 0.16226407885551453\n",
      "280 0.15536706149578094\n",
      "281 0.14883551001548767\n",
      "282 0.14257881045341492\n",
      "283 0.13657686114311218\n",
      "284 0.13080567121505737\n",
      "285 0.12530308961868286\n",
      "286 0.12003657966852188\n",
      "287 0.11496306955814362\n",
      "288 0.1101113110780716\n",
      "289 0.10551169514656067\n",
      "290 0.1010633260011673\n",
      "291 0.09679155051708221\n",
      "292 0.09272108972072601\n",
      "293 0.08882413059473038\n",
      "294 0.0851273462176323\n",
      "295 0.08156124502420425\n",
      "296 0.07813333719968796\n",
      "297 0.07484669983386993\n",
      "298 0.0717245489358902\n",
      "299 0.06872095167636871\n",
      "300 0.0658201277256012\n",
      "301 0.06307592988014221\n",
      "302 0.060438450425863266\n",
      "303 0.05790472403168678\n",
      "304 0.05549183860421181\n",
      "305 0.053175538778305054\n",
      "306 0.05096196383237839\n",
      "307 0.04882431775331497\n",
      "308 0.04679706692695618\n",
      "309 0.04484386369585991\n",
      "310 0.04298826679587364\n",
      "311 0.04118605703115463\n",
      "312 0.03948578983545303\n",
      "313 0.03783257678151131\n",
      "314 0.03625340387225151\n",
      "315 0.034733690321445465\n",
      "316 0.03331875056028366\n",
      "317 0.03191560506820679\n",
      "318 0.030593842267990112\n",
      "319 0.02933371439576149\n",
      "320 0.02812851034104824\n",
      "321 0.026956859976053238\n",
      "322 0.02583928033709526\n",
      "323 0.02477192133665085\n",
      "324 0.023732665926218033\n",
      "325 0.022766470909118652\n",
      "326 0.021815573796629906\n",
      "327 0.020918643102049828\n",
      "328 0.020061984658241272\n",
      "329 0.019241001456975937\n",
      "330 0.018450681120157242\n",
      "331 0.017693039029836655\n",
      "332 0.016971969977021217\n",
      "333 0.01627166196703911\n",
      "334 0.015601256862282753\n",
      "335 0.014965908601880074\n",
      "336 0.014357117004692554\n",
      "337 0.013773741200566292\n",
      "338 0.01321448665112257\n",
      "339 0.012680860236287117\n",
      "340 0.012166143395006657\n",
      "341 0.01167900487780571\n",
      "342 0.011206666007637978\n",
      "343 0.010750388726592064\n",
      "344 0.01031575072556734\n",
      "345 0.009894467890262604\n",
      "346 0.00949452631175518\n",
      "347 0.00911483820527792\n",
      "348 0.008752099238336086\n",
      "349 0.008408471941947937\n",
      "350 0.008070727810263634\n",
      "351 0.007752675097435713\n",
      "352 0.007443961687386036\n",
      "353 0.007147555705159903\n",
      "354 0.006868095137178898\n",
      "355 0.006600070744752884\n",
      "356 0.006335669197142124\n",
      "357 0.0060904365964233875\n",
      "358 0.005849865265190601\n",
      "359 0.005626999773085117\n",
      "360 0.005405309144407511\n",
      "361 0.005194443743675947\n",
      "362 0.004993109963834286\n",
      "363 0.004805798642337322\n",
      "364 0.004621653351932764\n",
      "365 0.004441020078957081\n",
      "366 0.004273266065865755\n",
      "367 0.004112506750971079\n",
      "368 0.003961220383644104\n",
      "369 0.0038112567272037268\n",
      "370 0.0036670127883553505\n",
      "371 0.0035294359549880028\n",
      "372 0.003398620756343007\n",
      "373 0.0032734673004597425\n",
      "374 0.0031568994745612144\n",
      "375 0.0030409423634409904\n",
      "376 0.0029272246174514294\n",
      "377 0.0028228878509253263\n",
      "378 0.002719379961490631\n",
      "379 0.0026204779278486967\n",
      "380 0.002525127725675702\n",
      "381 0.0024371189065277576\n",
      "382 0.0023500723764300346\n",
      "383 0.0022669127210974693\n",
      "384 0.002187466248869896\n",
      "385 0.0021133441478013992\n",
      "386 0.0020370427519083023\n",
      "387 0.0019681702833622694\n",
      "388 0.0018990825628861785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 0.001833415706641972\n",
      "390 0.0017718354938551784\n",
      "391 0.001712558325380087\n",
      "392 0.0016538570635020733\n",
      "393 0.0015992210246622562\n",
      "394 0.0015480640577152371\n",
      "395 0.0014974677469581366\n",
      "396 0.0014489905443042517\n",
      "397 0.001401303568854928\n",
      "398 0.0013557055499404669\n",
      "399 0.0013124904362484813\n",
      "400 0.0012692618183791637\n",
      "401 0.0012288331054151058\n",
      "402 0.0011907286243513227\n",
      "403 0.0011523641878739\n",
      "404 0.0011179442517459393\n",
      "405 0.001082771341316402\n",
      "406 0.0010500844800844789\n",
      "407 0.0010182132245972753\n",
      "408 0.0009867600165307522\n",
      "409 0.0009563190978951752\n",
      "410 0.0009297666256316006\n",
      "411 0.0009021004079841077\n",
      "412 0.0008751965360715985\n",
      "413 0.0008483387064188719\n",
      "414 0.0008225315250456333\n",
      "415 0.0007995629566721618\n",
      "416 0.0007764758192934096\n",
      "417 0.0007547899731434882\n",
      "418 0.0007324991747736931\n",
      "419 0.0007134071784093976\n",
      "420 0.0006926545174792409\n",
      "421 0.0006724224658682942\n",
      "422 0.0006537787849083543\n",
      "423 0.0006364690489135683\n",
      "424 0.0006198143237270415\n",
      "425 0.0006023072637617588\n",
      "426 0.0005864078411832452\n",
      "427 0.0005708509124815464\n",
      "428 0.000555632053874433\n",
      "429 0.0005402677925303578\n",
      "430 0.00052719033556059\n",
      "431 0.0005133839440532029\n",
      "432 0.0004996279603801668\n",
      "433 0.000486992415972054\n",
      "434 0.0004741645243484527\n",
      "435 0.00046157752512954175\n",
      "436 0.0004497121262829751\n",
      "437 0.00043940963223576546\n",
      "438 0.00042848673183470964\n",
      "439 0.0004185713187325746\n",
      "440 0.00040858579450286925\n",
      "441 0.0003981229674536735\n",
      "442 0.0003881082229781896\n",
      "443 0.00037922084447927773\n",
      "444 0.00037020162562839687\n",
      "445 0.00036163072218187153\n",
      "446 0.0003526084474287927\n",
      "447 0.00034420235897414386\n",
      "448 0.00033656603773124516\n",
      "449 0.0003291349858045578\n",
      "450 0.0003214920579921454\n",
      "451 0.00031349019263871014\n",
      "452 0.00030707771657034755\n",
      "453 0.0002999112184625119\n",
      "454 0.00029352199635468423\n",
      "455 0.00028739316621795297\n",
      "456 0.00028081523487344384\n",
      "457 0.00027446672902442515\n",
      "458 0.0002687910746317357\n",
      "459 0.0002636639983393252\n",
      "460 0.00025746802566573024\n",
      "461 0.00025191009626723826\n",
      "462 0.0002466757723595947\n",
      "463 0.00024205159570556134\n",
      "464 0.0002368485147599131\n",
      "465 0.00023187644546851516\n",
      "466 0.00022686462034471333\n",
      "467 0.00022234384960029274\n",
      "468 0.00021789503807667643\n",
      "469 0.00021362685947678983\n",
      "470 0.00020952642080374062\n",
      "471 0.00020538404351100326\n",
      "472 0.0002015039062825963\n",
      "473 0.00019716451060958207\n",
      "474 0.0001931556616909802\n",
      "475 0.00018959629232995212\n",
      "476 0.0001859860640252009\n",
      "477 0.00018220113997813314\n",
      "478 0.00017914458294399083\n",
      "479 0.00017602341540623456\n",
      "480 0.0001727727649267763\n",
      "481 0.0001693928352324292\n",
      "482 0.0001665472227614373\n",
      "483 0.00016355066327378154\n",
      "484 0.00016029912512749434\n",
      "485 0.0001575993373990059\n",
      "486 0.0001548683358123526\n",
      "487 0.00015239989443216473\n",
      "488 0.00014949942124076188\n",
      "489 0.00014679822197649628\n",
      "490 0.00014441355597227812\n",
      "491 0.00014148684567771852\n",
      "492 0.00013878585014026612\n",
      "493 0.00013670277257915586\n",
      "494 0.0001343042094958946\n",
      "495 0.00013148746802471578\n",
      "496 0.0001296147092944011\n",
      "497 0.00012747527216561139\n",
      "498 0.0001253906375495717\n",
      "499 0.00012324179988354445\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "input_dimension = 1000\n",
    "hidden_dimension = 100\n",
    "output_dimension = 10\n",
    "\n",
    "#Generate random tensors to hold inputs and outputs \n",
    "# Setting requires_grad = False indicates that we do not need to compute gradients\n",
    "# with respect to these tensors during the backward pass \n",
    "x = torch.randn(batch_size, input_dimension, device=device, dtype=dtype)\n",
    "y = torch.randn(batch_size, output_dimension, device=device, dtype=dtype)\n",
    "\n",
    "#Generate random weights for tensors \n",
    "#Setting requires_grad=True indicates that we want to compute gradients\n",
    "#with respect to these Tensors during the backward pass\n",
    "weight1 = torch.randn(input_dimension, hidden_dimension, device=device, dtype=dtype, requires_grad=True)\n",
    "weight2 = torch.randn(hidden_dimension, output_dimension, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for n in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors\n",
    "    # these are exactly the same operations we used to compute the forward pass\n",
    "    # using Tensors, but we do not need to keep references to intermediate values\n",
    "    # sine we are not implementing the backward pass by hand \n",
    "    y_pred = x.mm(weight1).clamp(min=0).mm(weight2)\n",
    "    \n",
    "    #Loss\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    #loss.item() gets the a scalar value held in the loss \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(n, loss.item())\n",
    "    \n",
    "    #Use autograd to compute backprop\n",
    "    #This call will compute the gradient of loss with respect to all Tensors with requires_grad=True\n",
    "    #After this call weight1.grad and weight2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to weight1 and weight2 respectively \n",
    "    loss.backward()\n",
    "    \n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this in autograd\n",
    "    #An alternative way is to operate on weight.data and weight.grad.data\n",
    "    # tensor.data gives a tensor that shares the storage with tensor\n",
    "    # but doesnt track history \n",
    "    # torch.optim.SGD can be used to achieve this\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weight1 -= learning_rate * weight1.grad\n",
    "        weight2 -= learning_rate * weight2.grad\n",
    "        \n",
    "        # Manually zero the gradients after updating weights \n",
    "        weight1.grad.zero_()\n",
    "        weight2.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
