{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: nn\n",
    "\n",
    "A fully connected ReLU network with one hidden layer, trained to predict y from x by minimizing squared Eucledian distance \n",
    "\n",
    "Note:\n",
    "PyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks; this is where the nn package can help. The nn package defines a set of Modules, which are in a way neural network layers that produce output from input and may have some trainable weights. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 688.6853637695312\n",
      "1 635.7244262695312\n",
      "2 589.9434814453125\n",
      "3 550.083984375\n",
      "4 515.1185302734375\n",
      "5 483.629638671875\n",
      "6 455.05548095703125\n",
      "7 429.166259765625\n",
      "8 405.27032470703125\n",
      "9 383.1319274902344\n",
      "10 362.560546875\n",
      "11 343.35577392578125\n",
      "12 325.3801574707031\n",
      "13 308.3205261230469\n",
      "14 292.0964050292969\n",
      "15 276.7087097167969\n",
      "16 262.1640625\n",
      "17 248.3519744873047\n",
      "18 235.24530029296875\n",
      "19 222.81497192382812\n",
      "20 210.9897918701172\n",
      "21 199.68276977539062\n",
      "22 188.92636108398438\n",
      "23 178.67356872558594\n",
      "24 168.9093475341797\n",
      "25 159.60931396484375\n",
      "26 150.76792907714844\n",
      "27 142.3562469482422\n",
      "28 134.35523986816406\n",
      "29 126.76847839355469\n",
      "30 119.59046936035156\n",
      "31 112.77050018310547\n",
      "32 106.29612731933594\n",
      "33 100.13944244384766\n",
      "34 94.32103729248047\n",
      "35 88.82373809814453\n",
      "36 83.62598419189453\n",
      "37 78.72298431396484\n",
      "38 74.09806823730469\n",
      "39 69.7412338256836\n",
      "40 65.63906860351562\n",
      "41 61.78065872192383\n",
      "42 58.14900207519531\n",
      "43 54.734642028808594\n",
      "44 51.52432632446289\n",
      "45 48.510807037353516\n",
      "46 45.67902755737305\n",
      "47 43.011749267578125\n",
      "48 40.5036735534668\n",
      "49 38.149845123291016\n",
      "50 35.939308166503906\n",
      "51 33.858001708984375\n",
      "52 31.90156364440918\n",
      "53 30.065458297729492\n",
      "54 28.340757369995117\n",
      "55 26.71271324157715\n",
      "56 25.177112579345703\n",
      "57 23.73432731628418\n",
      "58 22.3776798248291\n",
      "59 21.103487014770508\n",
      "60 19.907373428344727\n",
      "61 18.781728744506836\n",
      "62 17.723255157470703\n",
      "63 16.72953987121582\n",
      "64 15.796719551086426\n",
      "65 14.921294212341309\n",
      "66 14.0985689163208\n",
      "67 13.325010299682617\n",
      "68 12.597654342651367\n",
      "69 11.914077758789062\n",
      "70 11.27025318145752\n",
      "71 10.663652420043945\n",
      "72 10.09279727935791\n",
      "73 9.555242538452148\n",
      "74 9.046616554260254\n",
      "75 8.5673189163208\n",
      "76 8.116069793701172\n",
      "77 7.690157413482666\n",
      "78 7.288130283355713\n",
      "79 6.90911865234375\n",
      "80 6.551473140716553\n",
      "81 6.213469982147217\n",
      "82 5.8945465087890625\n",
      "83 5.593040466308594\n",
      "84 5.308150768280029\n",
      "85 5.038170337677002\n",
      "86 4.782767295837402\n",
      "87 4.54226541519165\n",
      "88 4.315313339233398\n",
      "89 4.1004414558410645\n",
      "90 3.897318124771118\n",
      "91 3.704807758331299\n",
      "92 3.5226731300354004\n",
      "93 3.3505935668945312\n",
      "94 3.1878507137298584\n",
      "95 3.0335052013397217\n",
      "96 2.887458562850952\n",
      "97 2.7489430904388428\n",
      "98 2.6176908016204834\n",
      "99 2.493147850036621\n",
      "100 2.375059127807617\n",
      "101 2.2630209922790527\n",
      "102 2.1566224098205566\n",
      "103 2.055739641189575\n",
      "104 1.9600082635879517\n",
      "105 1.8692102432250977\n",
      "106 1.7831242084503174\n",
      "107 1.7013949155807495\n",
      "108 1.6237114667892456\n",
      "109 1.5498515367507935\n",
      "110 1.4797176122665405\n",
      "111 1.4130183458328247\n",
      "112 1.3496534824371338\n",
      "113 1.2894399166107178\n",
      "114 1.2321470975875854\n",
      "115 1.1776766777038574\n",
      "116 1.1257896423339844\n",
      "117 1.0763583183288574\n",
      "118 1.0293325185775757\n",
      "119 0.9845510721206665\n",
      "120 0.941757321357727\n",
      "121 0.9009662866592407\n",
      "122 0.8621335029602051\n",
      "123 0.8251067399978638\n",
      "124 0.7898092269897461\n",
      "125 0.7561559081077576\n",
      "126 0.7240618467330933\n",
      "127 0.6934581995010376\n",
      "128 0.664309561252594\n",
      "129 0.6364979147911072\n",
      "130 0.6099756360054016\n",
      "131 0.5846604704856873\n",
      "132 0.560466468334198\n",
      "133 0.5373888611793518\n",
      "134 0.5153346061706543\n",
      "135 0.49426448345184326\n",
      "136 0.47413456439971924\n",
      "137 0.45490702986717224\n",
      "138 0.4365326464176178\n",
      "139 0.41897374391555786\n",
      "140 0.4021643102169037\n",
      "141 0.38608336448669434\n",
      "142 0.37070709466934204\n",
      "143 0.35600370168685913\n",
      "144 0.34195196628570557\n",
      "145 0.32848119735717773\n",
      "146 0.3155997395515442\n",
      "147 0.30326199531555176\n",
      "148 0.2914416790008545\n",
      "149 0.28011685609817505\n",
      "150 0.2692718505859375\n",
      "151 0.258880615234375\n",
      "152 0.2489357441663742\n",
      "153 0.23939339816570282\n",
      "154 0.2302442342042923\n",
      "155 0.22147993743419647\n",
      "156 0.2130696028470993\n",
      "157 0.20500370860099792\n",
      "158 0.19726711511611938\n",
      "159 0.1898486316204071\n",
      "160 0.18272866308689117\n",
      "161 0.17589765787124634\n",
      "162 0.169343039393425\n",
      "163 0.16305890679359436\n",
      "164 0.1570248156785965\n",
      "165 0.15122607350349426\n",
      "166 0.14565765857696533\n",
      "167 0.14030645787715912\n",
      "168 0.13516683876514435\n",
      "169 0.13023248314857483\n",
      "170 0.12549033761024475\n",
      "171 0.12093427032232285\n",
      "172 0.11655589938163757\n",
      "173 0.11234866082668304\n",
      "174 0.10830315202474594\n",
      "175 0.10441441833972931\n",
      "176 0.10067781805992126\n",
      "177 0.0970987007021904\n",
      "178 0.09365211427211761\n",
      "179 0.09033744037151337\n",
      "180 0.08714773505926132\n",
      "181 0.08407856523990631\n",
      "182 0.08111945539712906\n",
      "183 0.07827131450176239\n",
      "184 0.07553139328956604\n",
      "185 0.07289300113916397\n",
      "186 0.07035337388515472\n",
      "187 0.06790880858898163\n",
      "188 0.06555508077144623\n",
      "189 0.06329046934843063\n",
      "190 0.06110707297921181\n",
      "191 0.0590047687292099\n",
      "192 0.056979451328516006\n",
      "193 0.055027175694704056\n",
      "194 0.05314686521887779\n",
      "195 0.05133495107293129\n",
      "196 0.04958806931972504\n",
      "197 0.04790450632572174\n",
      "198 0.04628180339932442\n",
      "199 0.04471803084015846\n",
      "200 0.04321013391017914\n",
      "201 0.04175584390759468\n",
      "202 0.04035264253616333\n",
      "203 0.03900007903575897\n",
      "204 0.037695880979299545\n",
      "205 0.03643779456615448\n",
      "206 0.03522339090704918\n",
      "207 0.034052662551403046\n",
      "208 0.03292257338762283\n",
      "209 0.031831566244363785\n",
      "210 0.030778918415308\n",
      "211 0.02976357378065586\n",
      "212 0.028783872723579407\n",
      "213 0.027837470173835754\n",
      "214 0.02692405879497528\n",
      "215 0.026042064651846886\n",
      "216 0.025190681219100952\n",
      "217 0.02436860091984272\n",
      "218 0.023573901504278183\n",
      "219 0.022807052358984947\n",
      "220 0.022066693753004074\n",
      "221 0.021351339295506477\n",
      "222 0.020660486072301865\n",
      "223 0.019993159919977188\n",
      "224 0.01934840716421604\n",
      "225 0.01872551627457142\n",
      "226 0.0181235633790493\n",
      "227 0.017541982233524323\n",
      "228 0.016979875043034554\n",
      "229 0.01643655262887478\n",
      "230 0.01591150090098381\n",
      "231 0.015404273755848408\n",
      "232 0.014913812279701233\n",
      "233 0.014439507387578487\n",
      "234 0.013981112278997898\n",
      "235 0.013538000173866749\n",
      "236 0.013109627179801464\n",
      "237 0.01269526220858097\n",
      "238 0.012294464744627476\n",
      "239 0.011906860396265984\n",
      "240 0.01153211947530508\n",
      "241 0.011169582605361938\n",
      "242 0.010819163173437119\n",
      "243 0.01047998946160078\n",
      "244 0.010151837021112442\n",
      "245 0.009834491647779942\n",
      "246 0.009527421556413174\n",
      "247 0.009230176918208599\n",
      "248 0.008942597545683384\n",
      "249 0.008664400316774845\n",
      "250 0.008395055308938026\n",
      "251 0.00813446007668972\n",
      "252 0.007882294245064259\n",
      "253 0.007638175040483475\n",
      "254 0.007401932030916214\n",
      "255 0.007173224817961454\n",
      "256 0.006952006369829178\n",
      "257 0.006737719755619764\n",
      "258 0.00653030863031745\n",
      "259 0.006329754833132029\n",
      "260 0.006135260220617056\n",
      "261 0.005947077181190252\n",
      "262 0.0057647558860480785\n",
      "263 0.0055882129818201065\n",
      "264 0.005417304579168558\n",
      "265 0.00525174755603075\n",
      "266 0.005091469269245863\n",
      "267 0.004936249461025\n",
      "268 0.004785885103046894\n",
      "269 0.004640222527086735\n",
      "270 0.0044991327449679375\n",
      "271 0.004362471401691437\n",
      "272 0.004230197984725237\n",
      "273 0.0041020093485713005\n",
      "274 0.0039778100326657295\n",
      "275 0.0038574878126382828\n",
      "276 0.0037409011274576187\n",
      "277 0.003627944504842162\n",
      "278 0.0035185501910746098\n",
      "279 0.003412462305277586\n",
      "280 0.0033097006380558014\n",
      "281 0.003210133407264948\n",
      "282 0.0031136097386479378\n",
      "283 0.0030201016925275326\n",
      "284 0.0029294213745743036\n",
      "285 0.002841593697667122\n",
      "286 0.002756483620032668\n",
      "287 0.002674027578905225\n",
      "288 0.002594077493995428\n",
      "289 0.002516580745577812\n",
      "290 0.0024414409417659044\n",
      "291 0.0023685903288424015\n",
      "292 0.002297972561791539\n",
      "293 0.002229577163234353\n",
      "294 0.0021632465068250895\n",
      "295 0.002098919590935111\n",
      "296 0.0020365784876048565\n",
      "297 0.0019760900177061558\n",
      "298 0.0019174935296177864\n",
      "299 0.0018606696976348758\n",
      "300 0.00180555391125381\n",
      "301 0.0017521430272608995\n",
      "302 0.0017003436805680394\n",
      "303 0.0016500628553330898\n",
      "304 0.0016013621352612972\n",
      "305 0.0015540795866400003\n",
      "306 0.0015082521131262183\n",
      "307 0.00146390195004642\n",
      "308 0.0014209526125341654\n",
      "309 0.001379298628307879\n",
      "310 0.0013389120576903224\n",
      "311 0.001299718744121492\n",
      "312 0.0012617157772183418\n",
      "313 0.0012248399434611201\n",
      "314 0.0011890898458659649\n",
      "315 0.001154387486167252\n",
      "316 0.0011207456700503826\n",
      "317 0.0010880891932174563\n",
      "318 0.001056434353813529\n",
      "319 0.0010257222456857562\n",
      "320 0.0009959315648302436\n",
      "321 0.0009669945575296879\n",
      "322 0.0009389372426085174\n",
      "323 0.0009116883156821132\n",
      "324 0.000885268731508404\n",
      "325 0.0008596323896199465\n",
      "326 0.0008347664261236787\n",
      "327 0.0008106140303425491\n",
      "328 0.0007871701382100582\n",
      "329 0.0007644370198249817\n",
      "330 0.00074238411616534\n",
      "331 0.0007209762698039412\n",
      "332 0.0007001860067248344\n",
      "333 0.0006800105329602957\n",
      "334 0.0006604226655326784\n",
      "335 0.0006414269446395338\n",
      "336 0.0006229899590834975\n",
      "337 0.0006050752708688378\n",
      "338 0.0005876881768926978\n",
      "339 0.0005708234384655952\n",
      "340 0.0005544525338336825\n",
      "341 0.0005385446129366755\n",
      "342 0.0005231202230788767\n",
      "343 0.0005081387353129685\n",
      "344 0.0004936043987981975\n",
      "345 0.0004794785927515477\n",
      "346 0.00046578157343901694\n",
      "347 0.0004524658725131303\n",
      "348 0.000439549534348771\n",
      "349 0.00042700752965174615\n",
      "350 0.00041482795495539904\n",
      "351 0.00040300594992004335\n",
      "352 0.0003915214620064944\n",
      "353 0.00038037163903936744\n",
      "354 0.0003695468185469508\n",
      "355 0.00035903032403439283\n",
      "356 0.0003488197107799351\n",
      "357 0.0003389019111637026\n",
      "358 0.00032927346182987094\n",
      "359 0.000319930404657498\n",
      "360 0.0003108556556981057\n",
      "361 0.00030203250935301185\n",
      "362 0.00029347659437917173\n",
      "363 0.0002851513563655317\n",
      "364 0.000277076120255515\n",
      "365 0.00026923915720544755\n",
      "366 0.00026161668938584626\n",
      "367 0.00025421648751944304\n",
      "368 0.0002470332256052643\n",
      "369 0.00024005559680517763\n",
      "370 0.00023327310918830335\n",
      "371 0.00022668660676572472\n",
      "372 0.00022029383399058133\n",
      "373 0.00021407943859230727\n",
      "374 0.00020803969528060406\n",
      "375 0.00020217681594658643\n",
      "376 0.00019648572197183967\n",
      "377 0.00019095666357316077\n",
      "378 0.00018558435840532184\n",
      "379 0.00018036269466392696\n",
      "380 0.00017529747856315225\n",
      "381 0.00017036897770594805\n",
      "382 0.00016557984054088593\n",
      "383 0.00016093396698124707\n",
      "384 0.00015641599020455033\n",
      "385 0.00015203219663817436\n",
      "386 0.00014776468742638826\n",
      "387 0.00014362232468556613\n",
      "388 0.00013960161595605314\n",
      "389 0.00013569659495260566\n",
      "390 0.00013189927267376333\n",
      "391 0.00012820903793908656\n",
      "392 0.00012462239828892052\n",
      "393 0.00012113763659726828\n",
      "394 0.00011774888844229281\n",
      "395 0.00011446065036579967\n",
      "396 0.00011126328172395006\n",
      "397 0.00010816023132065311\n",
      "398 0.00010513978486414999\n",
      "399 0.0001022095893858932\n",
      "400 9.935908747138456e-05\n",
      "401 9.659190982347354e-05\n",
      "402 9.390097693540156e-05\n",
      "403 9.128267265623435e-05\n",
      "404 8.874307241057977e-05\n",
      "405 8.627648639958352e-05\n",
      "406 8.387651178054512e-05\n",
      "407 8.15455787233077e-05\n",
      "408 7.927688420750201e-05\n",
      "409 7.707489567110315e-05\n",
      "410 7.493238081224263e-05\n",
      "411 7.285709580173716e-05\n",
      "412 7.083305536070839e-05\n",
      "413 6.886592746013775e-05\n",
      "414 6.69540895614773e-05\n",
      "415 6.510180537588894e-05\n",
      "416 6.329545431071892e-05\n",
      "417 6.154328730190173e-05\n",
      "418 5.984002928016707e-05\n",
      "419 5.818273712066002e-05\n",
      "420 5.657182555296458e-05\n",
      "421 5.5005395552143455e-05\n",
      "422 5.348474223865196e-05\n",
      "423 5.2008410420967266e-05\n",
      "424 5.056846930528991e-05\n",
      "425 4.917199839837849e-05\n",
      "426 4.781767347594723e-05\n",
      "427 4.6493627451127395e-05\n",
      "428 4.521060691331513e-05\n",
      "429 4.396360236569308e-05\n",
      "430 4.275117680663243e-05\n",
      "431 4.1573734051780775e-05\n",
      "432 4.042765431222506e-05\n",
      "433 3.931408718926832e-05\n",
      "434 3.8233105442486703e-05\n",
      "435 3.717826621141285e-05\n",
      "436 3.6154204281046987e-05\n",
      "437 3.51597300323192e-05\n",
      "438 3.419313725316897e-05\n",
      "439 3.325215948279947e-05\n",
      "440 3.2339958124794066e-05\n",
      "441 3.1451480026589707e-05\n",
      "442 3.058355287066661e-05\n",
      "443 2.9745162464678288e-05\n",
      "444 2.8929764084750786e-05\n",
      "445 2.8135202228440903e-05\n",
      "446 2.7363590561435558e-05\n",
      "447 2.6613541194819845e-05\n",
      "448 2.5883700800477527e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449 2.5173907488351688e-05\n",
      "450 2.448266968713142e-05\n",
      "451 2.3813230654923245e-05\n",
      "452 2.3162168872659095e-05\n",
      "453 2.2527128749061376e-05\n",
      "454 2.1909416318521835e-05\n",
      "455 2.1312520402716473e-05\n",
      "456 2.072807001241017e-05\n",
      "457 2.016134385485202e-05\n",
      "458 1.9609513401519507e-05\n",
      "459 1.9074073861702345e-05\n",
      "460 1.8552615074440837e-05\n",
      "461 1.8046144759864546e-05\n",
      "462 1.7553082216181792e-05\n",
      "463 1.7075306459446438e-05\n",
      "464 1.6607369616394863e-05\n",
      "465 1.61555472004693e-05\n",
      "466 1.5715229892521165e-05\n",
      "467 1.5286370398825966e-05\n",
      "468 1.4870018276269548e-05\n",
      "469 1.4464682863035705e-05\n",
      "470 1.4068656128074508e-05\n",
      "471 1.3686739293916617e-05\n",
      "472 1.3314713214640506e-05\n",
      "473 1.29510517581366e-05\n",
      "474 1.2598925422935281e-05\n",
      "475 1.2256660738785286e-05\n",
      "476 1.1923724741791375e-05\n",
      "477 1.1599073332035914e-05\n",
      "478 1.1284442734904587e-05\n",
      "479 1.097708627639804e-05\n",
      "480 1.0677655154722743e-05\n",
      "481 1.0389316230430268e-05\n",
      "482 1.0106229638040531e-05\n",
      "483 9.832571777224075e-06\n",
      "484 9.565402251610067e-06\n",
      "485 9.30566147872014e-06\n",
      "486 9.053243957168888e-06\n",
      "487 8.807192898530047e-06\n",
      "488 8.569204510422423e-06\n",
      "489 8.337204235431273e-06\n",
      "490 8.110854651022237e-06\n",
      "491 7.891218956501689e-06\n",
      "492 7.678750080231111e-06\n",
      "493 7.469891897926573e-06\n",
      "494 7.267642104125116e-06\n",
      "495 7.070210813253652e-06\n",
      "496 6.878883596073138e-06\n",
      "497 6.693135674140649e-06\n",
      "498 6.51241998639307e-06\n",
      "499 6.335846592264716e-06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 64\n",
    "input_dimension = 1000\n",
    "hidden_dimension = 100\n",
    "output_dimension = 10\n",
    "\n",
    "x = torch.randn(batch_size, input_dimension)\n",
    "y = torch.randn(batch_size, output_dimension)\n",
    "\n",
    "#Use the nn package to define our model as a sequence of layers\n",
    "#nn.Sequential is a Module which contains other Modules, and a applies them in sequence\n",
    "#to produce its output. Each Linear Module computes output form input using a linear function,\n",
    "#and holds internal Tensors for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dimension, hidden_dimension),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(hidden_dimension, output_dimension),\n",
    ")\n",
    "\n",
    "#The nn package also contains definitions of populat loss functions; in this case\n",
    "# we will use Mean Squared Error (MSE) as our loss function\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "for n in range(500):\n",
    "    #Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When \n",
    "    # doing so you pass a Tensor of input data to the Module and it produces a Tensor of output data\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    #Compute and print loss. We pass Tensors containing the predicted and true values of y, \n",
    "    #and the loss function returns a Tensor containing the loss \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(n, loss.item())\n",
    "    \n",
    "    #Zero the gradients before running the backward pass\n",
    "    model.zero_grad()\n",
    "    \n",
    "    #Backward pass: compute gradient of the loss with respect to all the learnable \n",
    "    #parameters of the model. Internally, the parameters of each Module are stored in Tensors\n",
    "    #with required_grad = True, so this call will compute gradients for all learnable parameters \n",
    "    # in the model \n",
    "    loss.backward()\n",
    "    \n",
    "    #Update the weights using gradients descent. Each parameter is a Tensor so we can acsess \n",
    "    #and gradients like we did before\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
